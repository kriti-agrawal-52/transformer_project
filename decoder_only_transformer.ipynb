{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1f64a70-8940-49d2-8263-a8c177e8b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227c1416-d732-416b-874f-b3ac1d9a875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-16 18:44:05--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-05-16 18:44:06 (13.0 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the dataset for training \n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5a295-fde3-46ce-822a-e9180d62bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499d8bbe-114c-47e5-a541-1bb1ecf14537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "def load_dataset(filname):\n",
    "    try:\n",
    "        with open(filname, 'r') as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4e715-038b-4c0e-b529-627940becfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing_training():\n",
    "    def __init__(self, text, Batch, Time):\n",
    "        self.text = text\n",
    "        self.dataset_size = len(self.text)\n",
    "        self.vocab = sorted(set(self.text)) # number of distinct tokens in the dataset (for our model token is a character)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.Batch = Batch # we create a batch of 4 chunks which can be processed paralllely by our language model\n",
    "        self.Time = Time\n",
    "\n",
    "    def hash_for_tokenization(self):\n",
    "        # Tokenization is the process of splitting text into units (tokens) like characters, words, or subwords,\n",
    "        # and mapping each token to a unique numerical ID for model input.\n",
    "        self.str_to_int = {char:index for index, char in enumerate(self.vocab)}\n",
    "        self.int_to_str = {index:char for index, char in enumerate(self.vocab)}\n",
    "\n",
    "    def encoding(self, st: str):\n",
    "        return [self.str_to_int[x] for x in st]\n",
    "\n",
    "    def decoding(self, li: list):\n",
    "        return ''.join([self.int_to_str[x] for x in li])\n",
    "\n",
    "\n",
    "    def train_test_validation_split(self):\n",
    "        \"\"\"\n",
    "        Splits the dataset into train (81%), validation (9%), and test (10%).\n",
    "    \n",
    "        - First 90% is training+validation\n",
    "        - Last 10% is test\n",
    "        - From the 90%, 10% is taken as validation (i.e., 9% of total)\n",
    "        \"\"\"\n",
    "    \n",
    "        split_index_test = int(0.9 * len(text))\n",
    "        train_val_text = text[:split_index_test]\n",
    "        test_text = text[split_index_test:]\n",
    "    \n",
    "        split_index_val = int(0.9 * len(train_val_text))\n",
    "        train_text = train_val_text[:split_index_val]\n",
    "        val_text = train_val_text[split_index_val:]\n",
    "    \n",
    "        return train_text, val_text, test_text\n",
    "\n",
    "    def batch_index(self, split: str):\n",
    "        self.train_text, self.val_text, self.test_text = self.train_test_validation_split()\n",
    "        torch.manual_seed(1337)\n",
    "        if split == 'train':\n",
    "            data = train_text\n",
    "        elif split == 'validation':\n",
    "            data = val_text\n",
    "        else:\n",
    "            data = test_text\n",
    "        # we are seeding our torch random generator so that when we reproduce or rerurn this code, we always get same random numbers\n",
    "        batch_indices = torch.randint(len(data)-self.Time), (self.Batch,)) \n",
    "        # we are generating 4 random indices which can be any integers between 0 and len(data)-block_size which is Time\n",
    "        return batch_indices\n",
    "\n",
    "    def batch_of_chunks(self):\n",
    "        # creating x (input) and y (target) tensors for building and training our model\n",
    "        x = torch.stack([torch.tensor(data[ix: ix+self.Time]) for ix in batch_indices])\n",
    "        y = torch.stack([torch.tensor(data[ix+1: ix+self.Time+1]) for ix in batch_indices])\n",
    "        return x, y\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5ab65-b6c7-4e6f-b5db-5b92bd466230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
